<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"leonicehot.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"找到 ${hits} 個搜索結果（用時 ${time} 毫秒）","hits":"找到 ${hits} 個搜索結果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="簡介「Causal Relation」可以翻譯成「因果關係」。在哲學、科學、統計學和語言學等領域中，「因果關係」指的是一種事件或概念之間的關聯，其中一個事件被認為是另一個事件發生的原因或結果。換句話說，當一個事件或行為影響或導致另一個事件或行為發生時，我們稱之為「因果關係」。這種關係可以是直接的或間接的，但通常涉及一個事件引起另一個事件的變化或影響。 在科學研究中，確定因果關係對於理解事件之間的關">
<meta property="og:type" content="article">
<meta property="og:title" content="Trustworthy AI with Causality Perspectives">
<meta property="og:url" content="https://leonicehot.github.io/2023/08/08/2023/August/Trustworthy%20AI%20with%20Causality%20Perspectives/index.html">
<meta property="og:site_name" content="利醬の休憩房">
<meta property="og:description" content="簡介「Causal Relation」可以翻譯成「因果關係」。在哲學、科學、統計學和語言學等領域中，「因果關係」指的是一種事件或概念之間的關聯，其中一個事件被認為是另一個事件發生的原因或結果。換句話說，當一個事件或行為影響或導致另一個事件或行為發生時，我們稱之為「因果關係」。這種關係可以是直接的或間接的，但通常涉及一個事件引起另一個事件的變化或影響。 在科學研究中，確定因果關係對於理解事件之間的關">
<meta property="og:locale" content="zh_TW">
<meta property="article:published_time" content="2023-08-08T05:01:09.000Z">
<meta property="article:modified_time" content="2024-12-11T10:57:35.761Z">
<meta property="article:author" content="利醬">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://leonicehot.github.io/2023/08/08/2023/August/Trustworthy%20AI%20with%20Causality%20Perspectives/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-TW","comments":true,"permalink":"https://leonicehot.github.io/2023/08/08/2023/August/Trustworthy%20AI%20with%20Causality%20Perspectives/","path":"2023/08/08/2023/August/Trustworthy AI with Causality Perspectives/","title":"Trustworthy AI with Causality Perspectives"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Trustworthy AI with Causality Perspectives | 利醬の休憩房</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">利醬の休憩房</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜尋" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%B0%A1%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">簡介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%8B%E7%B4%B9"><span class="nav-number">2.</span> <span class="nav-text">介紹</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Trustworthy-AI"><span class="nav-number">3.</span> <span class="nav-text">Trustworthy AI</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reasoning"><span class="nav-number">4.</span> <span class="nav-text">Reasoning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Intrinsic-Explanation"><span class="nav-number">5.</span> <span class="nav-text">Intrinsic Explanation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Ad-hoc-explanation"><span class="nav-number">6.</span> <span class="nav-text">Ad-hoc explanation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Post-hoc-explanation"><span class="nav-number">7.</span> <span class="nav-text">Post-hoc explanation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Global-Explanation"><span class="nav-number">7.1.</span> <span class="nav-text">Global Explanation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Traditional-ML-Explanation"><span class="nav-number">7.2.</span> <span class="nav-text">Traditional ML Explanation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-agnostic-Explanation"><span class="nav-number">7.2.1.</span> <span class="nav-text">Model-agnostic Explanation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-specific-Explanation"><span class="nav-number">7.2.2.</span> <span class="nav-text">Model-specific Explanation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DNN-Representation-Explanation"><span class="nav-number">7.3.</span> <span class="nav-text">DNN Representation Explanation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Local-Explanation"><span class="nav-number">7.4.</span> <span class="nav-text">Local Explanation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-agnostic-Explanation-1"><span class="nav-number">7.4.1.</span> <span class="nav-text">Model-agnostic Explanation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-specific-Explanation-1"><span class="nav-number">7.4.2.</span> <span class="nav-text">Model-specific Explanation</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Membership-Inference"><span class="nav-number">8.</span> <span class="nav-text">Membership Inference</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Privacy-Attack"><span class="nav-number">9.</span> <span class="nav-text">Privacy Attack</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adversarial-Task"><span class="nav-number">10.</span> <span class="nav-text">Adversarial Task</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Adversarial-Attack"><span class="nav-number">10.1.</span> <span class="nav-text">Adversarial Attack</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adversarial-Robustness"><span class="nav-number">10.2.</span> <span class="nav-text">Adversarial Robustness</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adversarial-Defense"><span class="nav-number">10.3.</span> <span class="nav-text">Adversarial Defense</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bounded-Adversaries"><span class="nav-number">10.4.</span> <span class="nav-text">Bounded Adversaries</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adversarial-Sparsity"><span class="nav-number">10.5.</span> <span class="nav-text">Adversarial Sparsity</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adversarial-perturbations"><span class="nav-number">10.6.</span> <span class="nav-text">Adversarial perturbations</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Pearl%E2%80%99s-causal-hierarchy"><span class="nav-number">11.</span> <span class="nav-text">Pearl’s causal hierarchy</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Vanilla-Neural-Network"><span class="nav-number">12.</span> <span class="nav-text">Vanilla Neural Network</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">利醬</p>
  <div class="site-description" itemprop="description">部落格記載著電腦科學知識、基礎科學應用探討、工程技術之筆記。</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">145</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://leonicehot.github.io/2023/08/08/2023/August/Trustworthy%20AI%20with%20Causality%20Perspectives/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="利醬">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="利醬の休憩房">
      <meta itemprop="description" content="部落格記載著電腦科學知識、基礎科學應用探討、工程技術之筆記。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Trustworthy AI with Causality Perspectives | 利醬の休憩房">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Trustworthy AI with Causality Perspectives
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2023-08-08 13:01:09" itemprop="dateCreated datePublished" datetime="2023-08-08T13:01:09+08:00">2023-08-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2024-12-11 18:57:35" itemprop="dateModified" datetime="2024-12-11T18:57:35+08:00">2024-12-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分類於</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Science/" itemprop="url" rel="index"><span itemprop="name">Computer Science</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Science/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Science/Artificial-Intelligence/Trustworthy-AI/" itemprop="url" rel="index"><span itemprop="name">Trustworthy AI</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="文章字數">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">文章字數：</span>
      <span>8.7k</span>
    </span>
    <span class="post-meta-item" title="所需閱讀時間">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">所需閱讀時間 &asymp;</span>
      <span>16 分鐘</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="簡介"><a href="#簡介" class="headerlink" title="簡介"></a>簡介</h1><p>「Causal Relation」可以翻譯成「因果關係」。在哲學、科學、統計學和語言學等領域中，「因果關係」指的是一種事件或概念之間的關聯，其中一個事件被認為是另一個事件發生的原因或結果。換句話說，當一個事件或行為影響或導致另一個事件或行為發生時，我們稱之為「因果關係」。這種關係可以是直接的或間接的，但通常涉及一個事件引起另一個事件的變化或影響。</p>
<p>在科學研究中，確定因果關係對於理解事件之間的關聯性和原因和結果之間的聯繫至關重要。因此，科學家們使用不同的方法，如實驗設計和統計分析，來確定事件之間是否存在因果關係。</p>
<p>需要注意的是，僅僅因為兩個事件相互發生，並不一定意味著它們之間存在因果關係。要確定因果關係，需要進一步的研究和證據支持。</p>
<span id="more"></span>
<h1 id="介紹"><a href="#介紹" class="headerlink" title="介紹"></a>介紹</h1><p>因果推論（Causal Inference）是統計學和研究方法學的一個重要概念，它關注於識別和理解事件之間的因果關係，而不僅僅是觀察它們之間的相關性。因果推論的目標是通過控制其他可能的干擾變量，確定一個事件如何導致另一個事件的發生，從而建立起原因和結果之間的因果關係。</p>
<p>在因果推論中，重點是要確定是否存在一種因果關係，以及該關係的方向和強度。這通常需要使用特定的統計方法和實驗設計，以排除其他可能的解釋並確定因果關係。因果推論的目的是更深入地理解事件之間的關聯，並進一步探索造成某些結果的根本原因。</p>
<p>因果推論在醫學、社會科學、經濟學等領域中具有重要的應用。它幫助研究人員更準確地評估政策、干預措施或治療方法對事件產生的影響，並能夠做出更有信心的結論，而不僅僅是描述事件之間的相關性。</p>
<h1 id="Trustworthy-AI"><a href="#Trustworthy-AI" class="headerlink" title="Trustworthy AI"></a>Trustworthy AI</h1><p>「Trustworthy AI」可以翻譯為「可信賴的人工智慧」。這個概念指的是人工智慧系統在操作和做出決策時，能夠以可靠、透明和合乎道德的方式工作，並且能夠維護用戶、操作者和社會對其行為的信任。</p>
<p>實現可信賴的人工智慧涉及多個層面，包括：</p>
<ol>
<li><p>Interpretability and Explainability 透明度：人工智慧系統的運作和決策過程應該是可解釋和可理解的，使人們能夠理解系統是如何做出決策的。<br>Interpretability focuses on understanding the inner workings of the models, while explainability focuses on explaining the decisions made.</p>
</li>
<li><p>Fairness 公平性：人工智慧系統應該在對待不同的人群或群體時是公平的，不會引入不公正的偏見或歧視。</p>
</li>
<li><p>Private Privacy 隱私保護：人工智慧應該確保處理數據和信息時保護用戶的隱私，遵循相關的隱私法規和標準。</p>
</li>
<li><p>Adversarial Robustness (Security) 安全性：人工智慧系統應該設計成能夠預防和應對潛在的安全風險，防止被惡意濫用。<br>Topic regarding security mostly under the discussion of adversarial attack and defense</p>
</li>
<li><p>Robustness in generalization (Reliability) 可靠性：人工智慧系統在各種情況下都應該表現出穩定和可靠的行為，不會因為突發情況而失控或出現異常。</p>
</li>
<li><p>社會影響：人工智慧應該考慮到其在社會、經濟和文化層面的影響，確保對人類社會的影響是積極的。</p>
</li>
</ol>
<p>實現可信賴的人工智慧是保護用戶權益，確保技術進步與社會利益相一致的重要目標。</p>
<p>Ethics guidelines for trustworthy AI<br><a target="_blank" rel="noopener" href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai">https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai</a></p>
<h1 id="Reasoning"><a href="#Reasoning" class="headerlink" title="Reasoning"></a>Reasoning</h1><p>推論（Reasoning）是一種思考過程，通過分析、比較、結合和推斷已知的信息，從而得出新的結論、判斷或結果。推論是人類智慧的核心之一，它使我們能夠從已知的事實、假設或前提中推導出新的知識或結論，並用於解決問題、做出決策和理解世界。</p>
<p>推論可以分為不同的類型，包括：</p>
<ol>
<li><p>歸納推論（Inductive Reasoning）：基於觀察到的特定事例或案例，推斷出一般性規律或模式。例如，從觀察到的一系列事件中推斷出一個普遍的規律。</p>
</li>
<li><p>演繹推論（Deductive Reasoning）：基於已知的前提或假設，推斷出特定的結論。這種推論常常遵循著邏輯規則，從一個一般性陳述推導出更具體的結果。例如，從一個通用的法則中推導出特定情況下的結論。</p>
</li>
<li><p>轉喻推論（Analogical Reasoning）：通過比較兩個不同的情境或事物之間的相似性，從一個情境中的知識推斷出另一個情境中的結論。例如，通過比較兩個相似的問題，從一個問題的解決方法中得出對另一個問題的建議。</p>
</li>
<li><p>消解推論（Abductive Reasoning）：基於已知的觀察事實和可能的解釋，推斷出最有可能的解釋或假設。這種推論常用於解釋觀察到的現象，尤其是當有多種可能的解釋時。</p>
</li>
</ol>
<p>推論在解決問題、做出決策、科學研究以及日常思考中都起著重要作用。不同類型的推論可以幫助我們更好地理解和解釋世界，並從已知的信息中洞察出新的見解。</p>
<h1 id="Intrinsic-Explanation"><a href="#Intrinsic-Explanation" class="headerlink" title="Intrinsic Explanation"></a>Intrinsic Explanation</h1><p>內在解釋（Intrinsic Explanation）是指一種專注於內在因素和特性，以理解現象、行為或概念的解釋方法。它旨在揭示導致觀察結果的潛在機制、性質或品質，而不必考慮外部影響或背景。</p>
<p>內在解釋通常與外在解釋對比，外在解釋關注影響研究現象的外部因素、影響或環境。雖然內在解釋深入探討事物的基本本質，外在解釋則考慮外部力量如何與或塑造現象互動。</p>
<p>舉個例子，考慮一個經常志願幫助他人的人的行為。一個內在解釋可能會聚焦於該人的個人價值觀、同理心和利他主義感作為其行為背後的驅動力。另一方面，一個外在解釋可能涉及考慮該人的社會環境，如其成長背景、文化規範或同伴影響，這些可能是其志願工作的動機。</p>
<p>在各個領域，如心理學、哲學和科學，研究人員通常同時探索內在和外在解釋，以獲得對複雜現象更全面的理解。考慮到兩種觀點可以獲得對特定情況或行為影響因素的全面觀點。</p>
<h1 id="Ad-hoc-explanation"><a href="#Ad-hoc-explanation" class="headerlink" title="Ad-hoc explanation"></a>Ad-hoc explanation</h1><p>“Ad-hoc explanation” 在解釋可解釋性（Explainable AI，簡稱XAI）的上下文中，可以翻譯為「臨時解釋」、「特定情況解釋」或「即時說明」。這指的是在機器學習模型或人工智慧系統產生某個結果或預測時，根據特定情況或需求，即時提供的解釋，以協助用戶、操作者或受眾理解模型的決策依據或內部運作。</p>
<p>在可解釋性人工智慧中，「Ad-hoc explanation」強調了根據實際需求而快速提供解釋的能力，而不是事先固定的、通用的解釋方法。這種方式可以讓人們更好地理解模型的運作，增加對模型決策的信任度，並有助於確保人工智慧系統在應用中更加可信和可靠。</p>
<h1 id="Post-hoc-explanation"><a href="#Post-hoc-explanation" class="headerlink" title="Post-hoc explanation"></a>Post-hoc explanation</h1><p>“事後解釋”（Post-hoc explanation）是指在某事件或結果發生後，提供一個解釋。這個術語通常用於科學、社會科學以及數據分析等領域，用來理解最初未被預測或理解的觀察或結果。</p>
<p>在數據分析和機器學習的背景下，事後解釋涉及在事件發生後試圖理解特定模型為什麼做出了某種預測或決策。這可能涉及特徵重要性分析等技術，該技術可以確定對模型輸出產生最大影響的輸入變量。事後解釋對於深入瞭解複雜模型，使其更具可解釋性、透明性和可信性非常有價值。</p>
<p>然而，需要注意的是，事後解釋是有限的。它可能無法完全捕捉模型的決策過程的全部複雜性，並且所提供的解釋可能不總是完全準確或具有普適性。理想情況下，模型應從一開始就考慮到可解釋性和可解釋性，而不僅僅依賴於事後解釋來使其變得易於理解。</p>
<h2 id="Global-Explanation"><a href="#Global-Explanation" class="headerlink" title="Global Explanation"></a>Global Explanation</h2><h2 id="Traditional-ML-Explanation"><a href="#Traditional-ML-Explanation" class="headerlink" title="Traditional ML Explanation"></a>Traditional ML Explanation</h2><h3 id="Model-agnostic-Explanation"><a href="#Model-agnostic-Explanation" class="headerlink" title="Model-agnostic Explanation"></a>Model-agnostic Explanation</h3><h3 id="Model-specific-Explanation"><a href="#Model-specific-Explanation" class="headerlink" title="Model-specific Explanation"></a>Model-specific Explanation</h3><h2 id="DNN-Representation-Explanation"><a href="#DNN-Representation-Explanation" class="headerlink" title="DNN Representation Explanation"></a>DNN Representation Explanation</h2><h2 id="Local-Explanation"><a href="#Local-Explanation" class="headerlink" title="Local Explanation"></a>Local Explanation</h2><h3 id="Model-agnostic-Explanation-1"><a href="#Model-agnostic-Explanation-1" class="headerlink" title="Model-agnostic Explanation"></a>Model-agnostic Explanation</h3><h3 id="Model-specific-Explanation-1"><a href="#Model-specific-Explanation-1" class="headerlink" title="Model-specific Explanation"></a>Model-specific Explanation</h3><h1 id="Membership-Inference"><a href="#Membership-Inference" class="headerlink" title="Membership Inference"></a>Membership Inference</h1><p>會員推斷（Membership Inference）是一種隱私攻擊，旨在確定特定數據點是否在機器學習模型的訓練數據集中使用過。換句話說，它涉及試圖推斷某個特定的數據是否是模型在訓練過程中“記住”的實例之一。</p>
<p>在隱私是一個關注的情況下，例如在使用敏感或個人數據進行機器學習模型訓練時，會員推斷攻擊可能會揭示有關訓練數據集中個體的信息，即使模型並未明確設計為記住個別數據點。</p>
<p>會員推斷攻擊的基本思想是利用訓練模型的輸出，對於給定的輸入是否屬於訓練數據進行概率性或二元性的決策。攻擊者可能會利用模型對訓練和非訓練數據的響應之間的細微差異，潛在地利用模型行為中的模式或漏洞。</p>
<p>為了防範會員推斷攻擊，研究人員和從業者致力於開發保護隱私的機器學習技術。這些方法旨在通過減少模型可以從特定數據點中學到的信息量來保護訓練數據集中個體的隱私。技術包括差分隱私、數據擴充和對抗訓練，等等。</p>
<p>需要注意的是，會員推斷攻擊凸顯了在機器學習系統中確保隱私和安全的更廣泛挑戰，特別是在處理敏感數據時。</p>
<h1 id="Privacy-Attack"><a href="#Privacy-Attack" class="headerlink" title="Privacy Attack"></a>Privacy Attack</h1><p>隱私攻擊（Privacy Attack）是指針對個人或組織的隱私數據的有意或未經授權的收集、揭露、濫用或分析的行為。這種攻擊可能會導致個人敏感信息的外泄，危及隱私權和安全性。</p>
<p>隱私攻擊的類型和方法各種各樣，其中一些常見的包括：</p>
<ol>
<li><p>數據泄漏（Data Breach）：黑客或不當行為者未經授權地獲取並公開個人或組織的數據，如用戶帳戶信息、信用卡號碼等。</p>
</li>
<li><p>身份盜竊（Identity Theft）：攻擊者使用被盜取的個人信息來冒充他人身份，從而進行欺詐、非法活動或其他有害行為。</p>
</li>
<li><p>隱私侵犯（Privacy Invasion）：未經許可地收集、監視或分享個人的私人信息，如監視攝像頭、窺探通信等。</p>
</li>
<li><p>跟蹤和監控（Tracking and Surveillance）：通過數據收集和分析來跟蹤個人的活動、習慣和行為，從而獲得對其生活的深入洞察。</p>
</li>
<li><p>分析和推斷（Analysis and Inference）：通過統計分析、數據挖掘或機器學習等方法，從表面上無害的信息中推斷出個人的敏感信息。</p>
</li>
<li><p>社交工程（Social Engineering）：攻擊者通過誘騙、欺騙或操縱來引誘人們分享個人信息，從而達到不正當的目的。</p>
</li>
</ol>
<p>保護個人隱私的措施包括使用強密碼、定期更換密碼、限制個人信息的分享，並遵循數據保護和隱私法規。在數據處理和共享方面，應該實施加密、差分隱私、匿名化等技術，以最大程度地減少隱私攻擊的風險</p>
<h1 id="Adversarial-Task"><a href="#Adversarial-Task" class="headerlink" title="Adversarial Task"></a>Adversarial Task</h1><p>「對抗性任務」是指在機器學習和人工智能領域中的一類挑戰或問題，其目標是創建或解決牽涉到不同實體或系統組件之間對抗性關係的任務。這些任務通常涉及到一個實體試圖欺騙、操縱或對抗另一個實體的行動，從而產生一種競爭或對抗性的動態。</p>
<p>「對抗性任務」的概念與對抗性攻擊和防禦密切相關，但它擴展到更廣泛的場景和挑戰。對抗性任務可以存在於不同的領域，如計算機視覺、自然語言處理和遊戲等。以下是一些對抗性任務的示例：</p>
<ol>
<li><p>生成對抗網絡（GANs）：GANs 包括一個生成器和一個鑒別器網絡，它們進行一個對抗性的遊戲。生成器嘗試生成與真實數據難以區分的數據，而鑒別器則試圖區分真實數據和生成數據。</p>
</li>
<li><p>對抗性圖像標註：在這個任務中，目標是為圖像生成標題，但生成器和評估器處於對抗性關係，評估器試圖區分真實標題和生成標題。</p>
</li>
<li><p>文本對抗性挑戰：涉及在自然語言中生成或檢測對抗性示例，如生成迷惑語言模型的句子或檢測經過操縱的文本。</p>
</li>
<li><p>對抗性強化學習：在這個背景下，一個智能體學習與一個可以適應並對抗智能體行動的環境進行互動，以使學習過程更具挑戰性。</p>
</li>
<li><p>網絡安全和入侵檢測：檢測和對抗對電腦系統的攻擊或入侵嘗試等對抗性活動。</p>
</li>
<li><p>博弈論和策略：分析多個實體在對彼此的行動作出反應時的競爭場景，通常涉及對抗性或衝突性的利益。</p>
</li>
</ol>
<p>對抗性任務提供了有關機器學習系統的韌性、適應能力和戰略思維的見解。研究人員開發和研究這些任務，以了解模型和算法在複雜和對抗性環境中的限制和能力。</p>
<h2 id="Adversarial-Attack"><a href="#Adversarial-Attack" class="headerlink" title="Adversarial Attack"></a>Adversarial Attack</h2><p>對抗性攻擊（Adversarial Attack）是指在機器學習和人工智能領域中的一種技術，通過有意地對輸入數據進行微小的、精心製作的扰動，以欺騙或操縱機器學習模型的輸出。這些扰動對人類來說通常難以察覺，但可能會顯著影響模型的性能，導致它做出不正確的預測或分類。</p>
<p>對抗性攻擊利用機器學習算法，尤其是深度神經網絡的漏洞和限制，通過利用其輸入空間的高維特性。對抗攻擊的最終目標各有不同，可能包括：</p>
<ol>
<li><p>誤分類：通過向像素值添加微小的、精心製作的變化，迫使模型對輸入圖像進行誤分類。</p>
</li>
<li><p>有目標的攻擊：使模型將輸入分類為攻擊者所選擇的特定目標類別，而不僅僅是造成任何誤分類。</p>
</li>
<li><p>黑盒攻擊：在沒有直接訪問目標模型的架構或參數的情況下，僅使用其輸出響應生成對抗性示例。</p>
</li>
<li><p>可轉移性：經常可以將為一個模型生成的對抗性示例迷惑其他在相似任務上訓練的模型，展示了攻擊的可轉移性。</p>
</li>
<li><p>物理攻擊：操縱現實世界的物體（例如添加貼紙或圖案），以在被攝像頭或傳感器捕獲時引起誤分類。</p>
</li>
<li><p>文本攻擊：以某種方式操縱或改變文本，使語言模型生成非預期或有偏見的輸出。</p>
</li>
</ol>
<p>對抗性攻擊引出了關於機器學習模型的穩健性、安全性和可靠性的重要問題。該領域的研究人員和從業者致力於開發對抗性防禦方法，這些方法旨在通過使用對抗性示例訓練模型、修改模型架構或添加額外的安全層來提高模型對對抗性扰動的抵抗力。</p>
<p>對抗性攻擊和防禦是人工智能領域中持續的研究領域，對於眾多應用領域具有重要意義，包括計算機視覺、自然語言處理、自動駕駛車輛和網絡安全。</p>
<h2 id="Adversarial-Robustness"><a href="#Adversarial-Robustness" class="headerlink" title="Adversarial Robustness"></a>Adversarial Robustness</h2><p>對抗性韌性（Adversarial Robustness）是指機器學習模型抵抗對抗性攻擊的能力，也就是在面對經過微小扰動的輸入數據時，能夠保持穩定的性能並產生正確的輸出。具有高度對抗性韌性的模型能夠有效地識別和應對可能導致誤分類或其他錯誤行為的對抗性示例。</p>
<p>對抗性韌性是機器學習模型在實際應用中的重要屬性，特別是在面對可能的安全風險和攻擊時。強大的對抗性韌性可以減輕對抗性攻擊造成的影響，並提高模型的可靠性。為了提高對抗性韌性，研究人員和從業者採取了多種方法，包括：</p>
<ol>
<li><p>對抗性訓練：在訓練過程中，引入對抗性示例，使模型能夠學習如何處理這些扰動，從而增強其對抗性韌性。</p>
</li>
<li><p>模型架構修改：調整模型的架構，使其能夠更好地捕捉對抗性示例的特徵，從而提高對抗性韌性。</p>
</li>
<li><p>防禦機制：添加特定的防禦層或機制，例如對抗性過濾、特徵轉換等，以增加模型對對抗性攻擊的防禦能力。</p>
</li>
<li><p>數據增強：通過對訓練數據進行扰動或變換，幫助模型更好地適應各種對抗性示例。</p>
</li>
<li><p>遷移學習：從已經具有一定對抗性韌性的模型中學習，以改善目標模型的對抗性韌性。</p>
</li>
</ol>
<p>對抗性韌性的研究仍在持續進行，並且在實際應用中具有重要意義，尤其是在涉及安全性、隱私保護和信任度的領域。</p>
<h2 id="Adversarial-Defense"><a href="#Adversarial-Defense" class="headerlink" title="Adversarial Defense"></a>Adversarial Defense</h2><p>對抗性防禦（Adversarial Defense）是指在機器學習和人工智能領域中，針對對抗性攻擊（Adversarial Attack）開發的技術和方法，旨在增強機器學習模型對於對抗性示例的韌性，從而提高模型的安全性和可靠性。</p>
<p>對抗性攻擊通常通過微小的、精心製作的扰動來操縱模型的輸出，可能導致錯誤的預測或分類。對抗性防禦旨在減少這些攻擊的影響，使模型在面對對抗性示例時能夠保持穩定的性能。</p>
<p>一些常見的對抗性防禦方法包括：</p>
<ol>
<li><p>對抗性訓練：在訓練過程中引入對抗性示例，使模型能夠適應這些扰動，從而增強其對抗性韌性。</p>
</li>
<li><p>模型修正：對模型進行修改，以增強其對對抗性攻擊的防禦能力，如添加對抗性過濾器或正則化。</p>
</li>
<li><p>檢測方法：開發檢測模型，以識別可能是對抗性示例的輸入，並在必要時拒絕處理這些輸入。</p>
</li>
<li><p>數據預處理：對輸入數據進行預處理，使其對對抗性攻擊更加韌性，如通過濾或降噪。</p>
</li>
<li><p>特徵轉換：對輸入進行轉換，以削弱對抗性示例的影響，同時保持模型的性能。</p>
</li>
<li><p>集成防禦：將多種不同的防禦方法結合在一起，以增強對抗性韌性。</p>
</li>
</ol>
<p>對抗性防禦是一個重要的研究領域，因為它關乎機器學習模型在實際應用中的安全性和可信賴性。然而，對抗性防禦也可能面臨困難，因為攻擊者可能會不斷地提出新的攻擊方法，需要不斷地改進防禦策略。</p>
<h2 id="Bounded-Adversaries"><a href="#Bounded-Adversaries" class="headerlink" title="Bounded Adversaries"></a>Bounded Adversaries</h2><p>“Bounded Adversaries” 是一個常見於計算機科學和安全領域的術語，特別是在有關機器學習、人工智能和系統安全性方面的研究中。</p>
<p>“Bounded Adversaries” 指的是一種限制了攻擊者行為能力的概念。在這種情況下，攻擊者的行動受到某些限制或約束，例如有限的計算能力、有限的資源、有限的時間等。這樣的限制可以使得系統更容易應對可能的攻擊。</p>
<p>例如，在機器學習中，我們可以考慮 “Bounded Adversaries” 的情況，即假設攻擊者只能在有限的範圍內進行修改或攻擊輸入數據，而不能進行無限制的操作。這種假設可以幫助我們設計更健壯(Robustness)的機器學習模型，能夠在受到有限攻擊時保持良好的性能。</p>
<p>總之，”Bounded Adversaries” 強調了限制攻擊者行動能力的概念，有助於增強系統和算法對各種可能攻擊的抵抗能力。</p>
<h2 id="Adversarial-Sparsity"><a href="#Adversarial-Sparsity" class="headerlink" title="Adversarial Sparsity"></a>Adversarial Sparsity</h2><p>在機器學習和深度學習領域中，「對抗性稀疏性」指的是一種技術，通常應用於神經網絡，旨在讓模型學習到在表示數據時使用更少的特徵或輸入。這種方法的靈感來自「稀疏性」，即模型的某些部分只使用少數幾個重要特徵，而忽略其他特徵，從而簡化模型並提高其可解釋性。</p>
<p>在「對抗性稀疏性」中，通常會引入「對抗性」的元素，這意味著引入一個額外的模型（稱為「對抗性網絡」），該模型的目標是通過對原始模型進行壓縮或限制來鼓勵原始模型學習到更少的特徵。這種壓縮通常是通過降低模型的輸入或中間表示的維度來實現的。</p>
<p>「對抗性稀疏性」的主要目標之一是在保持模型性能的同時，減少模型的計算成本、記憶需求和過擬合的風險。這種技術有助於開發更高效、更輕量的模型，特別適用於在資源受限的環境中部署機器學習應用。</p>
<h2 id="Adversarial-perturbations"><a href="#Adversarial-perturbations" class="headerlink" title="Adversarial perturbations"></a>Adversarial perturbations</h2><p>「對抗性干擾」是指在機器學習和深度學習模型的背景下，對輸入數據進行微小但精心設計的更改，旨在使模型產生錯誤的預測或分類。這些干擾對人類來說通常是難以察覺的，但可能對模型的行為產生重大影響。</p>
<p>對抗性干擾是對抗性攻擊的一種形式，攻擊者通過引入這些微小變化來利用模型決策過程中的漏洞。此類攻擊的目標是創建與原始數據幾乎相同但會使模型產生意外和錯誤輸出的輸入。</p>
<p>對抗性干擾有不同的類型：</p>
<ol>
<li>白盒攻擊： 攻擊者完全了解模型的結構和參數，並製作干擾以欺騙模型。</li>
<li>黑盒攻擊： 攻擊者並不完全了解模型的內部，但仍試圖生成能夠欺騙模型的干擾輸入。</li>
<li>轉移攻擊： 攻擊者在一個模型上生成對抗性示例，然後在另一個模型上測試它們，利用對抗性干擾的可轉移性。</li>
</ol>
<p>對抗性干擾可能發生在各個領域，例如圖像分類、語音識別和自然語言處理。它們突顯了機器學習模型的脆弱性，以及創建強大且可靠的人工智慧系統所面臨的挑戰。</p>
<p>機器學習領域的研究人員和從業者致力於開發技術來防禦對抗性干擾，例如對抗性訓練、使用強韌性架構以及提高模型的整體安全性。</p>
<h1 id="Pearl’s-causal-hierarchy"><a href="#Pearl’s-causal-hierarchy" class="headerlink" title="Pearl’s causal hierarchy"></a>Pearl’s causal hierarchy</h1><p>皮爾的因果階層（Pearl’s causal hierarchy）是指研究因果關係的一個框架，用於理解不同層次的因果推斷和問題。這個階層分為三個層次，每個層次都涉及不同類型的因果推理和問題：</p>
<ol>
<li><p>觀察性因果關係（Observational Causation）：這是因果階層的第一層，涉及在觀察到某一事件或條件X的情況下，評估事件或條件Y發生的可能性。這通常是基於觀察到的資料進行的因果推斷。</p>
</li>
<li><p>干預性因果關係（Interventionist Causation）：這是因果階層的第二層，涉及對系統進行干預或實驗，並評估在不同干預條件下事件或條件Y的可能性。這是針對假設性情境進行因果推理的層次。</p>
</li>
<li><p>反事實因果關係（Counterfactual Causation）：這是因果階層的第三層，處理的是如果過去的情況不同，那麼結果可能會有所不同。這涉及想像不同的過去情境並評估其影響。</p>
</li>
</ol>
<p>皮爾的因果階層幫助我們理解和分析因果關係在不同情境下的不同層次，從而更好地進行因果推斷和解釋。</p>
<h1 id="Vanilla-Neural-Network"><a href="#Vanilla-Neural-Network" class="headerlink" title="Vanilla Neural Network"></a>Vanilla Neural Network</h1><p>「Vanilla Neural Network」簡稱為「經典神經網絡」或「基本神經網絡」。這是指最基本形式的神經網絡架構，通常由一個或多個連接的神經層組成，每個神經層包含多個神經元（或稱為神經元）。</p>
<p>經典神經網絡通常由輸入層、隱藏層和輸出層組成。每一個神經元都與前一層的所有神經元相連，並且具有權重和偏差，這些參數用來調整輸入信號的影響。每個神經元將其輸入信號經過加權和偏差處理後，通過一個激活函數（如Sigmoid、ReLU等）來產生輸出。</p>
<p>經典神經網絡在許多機器學習任務中表現出色，但也有一些限制。隨著深度學習的發展，更複雜的神經網絡架構如卷積神經網絡（CNNs）和循環神經網絡（RNNs）等已經優化了特定領域的性能。然而，經典神經網絡作為一個基本的概念，仍然對理解神經網絡的運作和基本原理至關重要。</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/07/26/2023/July/TensorRT/" rel="prev" title="TensorRT">
                  <i class="fa fa-angle-left"></i> TensorRT
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/08/14/2023/August/Representation-Learning/" rel="next" title="Representation learning">
                  Representation learning <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">利醬</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="總字數">293k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="所需總閱讀時間">8:52</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM=" crossorigin="anonymous">



</body>
</html>
